@article{Chai1999,
abstract = {This paper addresses our proposed method to automatically segment$\backslash$nout a person's face from a given image that consists of a$\backslash$nhead-and-shoulders view of the person and a complex background scene.$\backslash$nThe method involves a fast, reliable, and effective algorithm that$\backslash$nexploits the spatial distribution characteristics of human skin color. A$\backslash$nuniversal skin-color map is derived and used on the chrominance$\backslash$ncomponent of the input image to detect pixels with skin-color$\backslash$nappearance. Then, based on the spatial distribution of the detected$\backslash$nskin-color pixels and their corresponding luminance values, the$\backslash$nalgorithm employs a set of novel regularization processes to reinforce$\backslash$nregions of skin-color pixels that are more likely to belong to the$\backslash$nfacial regions and eliminate those that are not. The performance of the$\backslash$nface-segmentation algorithm is illustrated by some simulation results$\backslash$ncarried out on various head-and-shoulders test images. The use of face$\backslash$nsegmentation for video coding in applications such as videotelephony is$\backslash$nthen presented. We explain how the face-segmentation results can be used$\backslash$nto improve the perceptual quality of a videophone sequence encoded by$\backslash$nthe H.261-compliant coder},
author = {Chai, Douglas and Ngan, King N.},
doi = {10.1109/76.767122},
file = {:home/anirudt/Downloads/00767122.pdf:pdf},
isbn = {1051-8215},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
mendeley-groups = {DIP - GR},
number = {4},
pages = {551--564},
title = {{Face segmentation using skin-color map in videophone applications}},
volume = {9},
year = {1999}
}


@article{zatlab,
author = {Baltazar, Andr{\'{e}} and Martins, Lg and Cardoso, Js},
file = {:home/anirudt/Projects/coursework/sem9/DIP/papers/2012ABaltazarARTECH.pdf:pdf},
journal = {6th International Conference on Digital Arts (ARTECH 2012)},
mendeley-groups = {DIP - GR},
title = {{ZATLAB: A Gesture Analysis System to Music Interaction}},
url = {http://www.inescporto.pt/{~}jsc/publications/conferences/2012ABaltazarARTECH.pdf},
year = {2012}
}

@article{musicpro,
abstract = {This paper proposes a new perceptual interface for the control of computer-based music production. We address the constraints imposed by the use of musical meta-instruments during live performance or rehearsal by tracking feet motion relatively to a visual keyboard. The visual attribute stands for the fact that, unlike its physical counterpart, our keyboard does not involve any force feedback during key-presses. The proposed tracking algorithm is structured on two levels, namely a coarse level for foot regions, and a fine level for foot tips. Tracking works in real-time and handles efficiently feet regions merging/unmerging due to spatial proximity and cast shadows. The output of the tracking is used for the spatiotemporal detection of key-"press" events. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Jean, Fr{\'{e}}d{\'{e}}ric and Albu, Alexandra Branzan},
doi = {10.1016/j.image.2008.04.013},
file = {:home/anirudt/Projects/coursework/sem9/DIP/papers/The{\_}visual{\_}keyboard{\_}Real-time{\_}feet{\_}tracking{\_}for{\_}th.pdf:pdf},
isbn = {4186563594},
issn = {09235965},
journal = {Signal Processing: Image Communication},
keywords = {Computer vision,Motion tracking,Real-time event detection},
mendeley-groups = {DIP - GR},
number = {7},
pages = {505--515},
title = {{The visual keyboard: Real-time feet tracking for the control of musical meta-instruments}},
volume = {23},
year = {2008}
}


@inproceedings{pixelskin,
  title={A survey on pixel-based skin color detection techniques},
  author={Vezhnevets, Vladimir and Sazonov, Vassili and Andreeva, Alla},
  booktitle={Proc. Graphicon},
  volume={3},
  pages={85--92},
  year={2003},
  organization={Moscow, Russia}
}

